{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "This notebook shows how to use the Unity ML-Agents environment, how to implement a DQN agent that utilizes an experience replay buffer and fixed Q-targets. The goal is to train an agent to collect yellow bananas in a 2D gameplay while avoiding blue bananas in the given environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. The Learning Algorithm\n",
    "\n",
    "The basis of the implemented learning algorithm is called Sarsamax or Q-learning. It's an off-policy Temporal-Difference (TD) control method that updates the value function estimate after every ($C$) time step/s. It is guaranteed to converge as long as the stepsize parameter LR (the learning rate) is sufficiently small and epsilon is chosen to satisfy the Greedy in the Limit with Infinite Exploration (GLIE) conditions. Algorithm taken from *Reinforcment Learning, An introduction, second edition, by Richard S. Sutton and Andrew G. Barto*.\n",
    "\n",
    "<img src=\"qlearning.png\" width=\"500\" align=\"center\" title=\"Q-Learning Algorithm\">\n",
    "\n",
    "We implemented a version of Deep Q-Learning or DQN based on Mnih et al. (paper: [Human-level control through deep reinforcement learning](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)) that uses deep neural networks to approximate the optimal action-value function and enhances performance via two techniques: *Experience Replay*, and *Fixed Q-targets*. The Q-learning update at iteration $i$ uses the following loss\n",
    "function:\n",
    "\n",
    "<img src=\"q-update.png\" width=\"350\" align=\"center\" title=\"Q-Learning Update at iteration i\">\n",
    "\n",
    ">in which $\\gamma$ is the discount factor determining the agentâ€™s horizon, $\\theta_{i}$ are the parameters of the Q-network at iteration $i$ and $\\theta_{i}^{-b}$ are the network parameters used to compute the target at iteration $i$. \n",
    "\n",
    "The chosen hyperparameters for our implementation are:\n",
    "- SEED = 0\n",
    "- GAMMA = 0.99\n",
    "- EPS_STRT = 1.0\n",
    "- EPS_END = 0.002\n",
    "- EPS_DECAY = 0.99\n",
    "- LR = 0.002\n",
    "- TAU = 0.001\n",
    "- BUFFER_SIZE = 100000 \n",
    "- BATCH_SIZE = 64\n",
    "- C = 4\n",
    "\n",
    "The chosen model architecture for the (two) neural nets are as follows and we use ```Dropout(p=0.02)```:\n",
    "\n",
    "```python\n",
    "QNet(\n",
    "  (fc1): Linear(in_features=37, out_features=128, bias=True)\n",
    "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
    "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
    "  (fc4): Linear(in_features=64, out_features=64, bias=True)\n",
    "  (fc5): Linear(in_features=64, out_features=4, bias=True)\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment\n",
    "\n",
    "Importing some necessary packages. If the code cell below returns an error, please double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/) properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Before running the code cell below_**: if you do not run this notebook on Mac OSX go back to the ```README.md``` file (see Dependencies 3.) to download a different version (Widows, Linux) of the ```Banana.app``` file and change the `file_name` path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "This is how a trained agent moves inside the environment (.gif taken from Udacity):\n",
    "\n",
    "<img src=\"banana.gif\" width=\"450\" align=\"center\" title=\"Banana environment\">\n",
    "\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will see how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, when it selects an action (uniformly) at random at each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment (check the ```README.md``` file for more details).  \n",
    "\n",
    "Of course, the goal is to train an agent that is able to use its experience to gradually choose better actions when interacting with the environment!\n",
    "\n",
    "**_Only uncomment and run the next two cells if you want to see a random agent._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nenv_info = env.reset(train_mode=False)[brain_name] # reset the environment\\nstate = env_info.vector_observations[0]            # get the current state\\nscore = 0                                          # initialize the score\\nwhile True:\\n    action = np.random.randint(action_size)        # select an action\\n    env_info = env.step(action)[brain_name]        # send the action to the environment\\n    next_state = env_info.vector_observations[0]   # get the next state\\n    reward = env_info.rewards[0]                   # get the reward\\n    done = env_info.local_done[0]                  # see if episode has finished\\n    score += reward                                # update the score\\n    state = next_state                             # roll over the state to next time step\\n    if done:                                       # exit loop if episode finished\\n        break\\n    \\nprint(\"Score: {}\".format(score))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training an agent to solve the environment\n",
    "\n",
    "In the following you find implementations of ```run_dqn()```, ```Agent()```, ```QNet()```, and ```ReplayBuffer()```. The environment is considered solved when the agent is able to receive an average reward (over 100 episodes) of at least +13. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dqn(agent, num_episodes, eps_strt, eps_end, eps_decay):\n",
    "    \"\"\" Run the dqn algorithm with an agent on given environment.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        agent: agent object (see Agent())\n",
    "        nume_episodes: maximum number of episodes to train\n",
    "        eps_strt: epsilon start value\n",
    "        eps_end: epsilon min value\n",
    "        eps_decay: epsilon decay value\n",
    "        \n",
    "    \"\"\"\n",
    "    scores = list()\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps = eps_strt\n",
    "    \n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0] # get the current state\n",
    "        score = 0 \n",
    "        \n",
    "        while True:\n",
    "            action = agent.select_action(state, eps)\n",
    "            env_info = env.step(action)[brain_name] \n",
    "            next_state, reward, done = env_info.vector_observations[0], env_info.rewards[0], env_info.local_done[0]\n",
    "            agent.step(state, action, next_state, reward, done)\n",
    "            score += reward\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        scores.append(score)\n",
    "        scores_window.append(score)\n",
    "        eps = max(eps*eps_decay, eps_end)       # update epsilon\n",
    "        \n",
    "        print('\\r{}/{} Episode. Avg score {:.3f}'.format(i_episode, num_episodes, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\r{}/{} Episode. Avg score {:.3f}'.format(i_episode, num_episodes, np.mean(scores_window)))\n",
    "        \n",
    "        if np.mean(scores_window) >= 13:\n",
    "            # to solve the environment get an average score of +13 over 100 consecutive episodes.\n",
    "            print('\\rEnvironment solved after {} episodes'.format(i_episode))\n",
    "            torch.save(agent.qnet_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "SEED = 0               # random seed\n",
    "GAMMA = 0.99           # discounting factor\n",
    "EPS_STRT = 1.0         # epsilon start value\n",
    "EPS_END = 0.002        # epsilon end/minimum value\n",
    "EPS_DECAY = 0.99       # epsilon decay factor\n",
    "LR = 0.002             # learning rate\n",
    "TAU = 0.001            # factor for target soft update\n",
    "BUFFER_SIZE = 100000   # max replay buffer size\n",
    "BATCH_SIZE = 64        # batch size\n",
    "C = 4                  # update every C parameter\n",
    "\n",
    "device = torch.device('cuda0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    \"\"\" Agent that implements the dqn algorithm with experience replay and fixed q-targets \n",
    "    to interact with and learn from the game environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\" Initialize the Agent object.\n",
    "        Params\n",
    "        ======\n",
    "            state_size: dimension of each state\n",
    "            action_size: dimension of each action\n",
    "            seed: random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = np.random.seed(seed)\n",
    "        self.step_t = 0 # init for update every C time steps\n",
    "        \n",
    "        # QNetwork\n",
    "        self.qnet_local = QNet(state_size, action_size, SEED)\n",
    "        self.qnet_target = QNet(state_size, action_size, SEED)\n",
    "        self.optimizer = optim.Adam(self.qnet_local.parameters(), lr=LR)\n",
    "        \n",
    "        # Replay buffer\n",
    "        self.buffer = ReplayBuffer(BUFFER_SIZE, BATCH_SIZE, device, SEED)\n",
    "\n",
    "    def select_action(self, state, eps):\n",
    "        \"\"\" Return epsilon greedy action.\"\"\"\n",
    "        self.qnet_local.eval()\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device) # torch.Size([1, 37])\n",
    "        do_explore = np.random.random() < eps\n",
    "        \n",
    "        if do_explore: # random action\n",
    "            action = np.random.choice(np.arange(self.action_size))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                action = np.argmax(self.qnet_local.forward(state).cpu().data.numpy()) # .cpu().data.numpy() vs.numpy() ?\n",
    "        \n",
    "        self.qnet_local.train()\n",
    "        return action\n",
    "    \n",
    "    def step(self, state, action, next_state, reward, done):\n",
    "        \"\"\" Add experience to memory and make learning step.\"\"\"\n",
    "        self.buffer.add(state, action, next_state, reward, done)\n",
    "    \n",
    "        self.step_t = (self.step_t + 1) % C\n",
    "        if self.step_t == 0:\n",
    "            if len(self.buffer) > BATCH_SIZE:\n",
    "                self.learn()\n",
    "    \n",
    "    def learn(self):\n",
    "        \"\"\" Get batch of samples and update network parameters.\"\"\"\n",
    "        states, actions, next_states, rewards, dones = self.buffer.sample()\n",
    "        self.optimizer.zero_grad()\n",
    "        q_expected = self.qnet_local.forward(states).gather(1, actions) # torch.Size([64, 1])\n",
    "        q_targets_next = self.qnet_target.forward(next_states).max(1)[0].unsqueeze(1) # torch.Size([64, 1])\n",
    "        q_targets = rewards + (GAMMA * q_targets_next * (1 - dones))\n",
    "        loss = F.mse_loss(q_expected, q_targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.soft_update_target()\n",
    "    \n",
    "    def soft_update_target(self):\n",
    "        \"\"\" Copy local params to target params via Tau * local.params + (1-Tau) * target.params\"\"\"\n",
    "        for target_params, local_params in zip(self.qnet_target.parameters(), self.qnet_local.parameters()):\n",
    "            target_params.data.copy_(TAU * local_params.data + (1 - TAU) * target_params.data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    \"\"\" Policy neural network model that maps states to actions.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\" Initialize the neural net.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        state_size: dimension of each input state\n",
    "        action_size: dimension of each output\n",
    "        seed: random seed\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.dropout = nn.Dropout(p=0.02)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.fc5 = nn.Linear(64, action_size)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "\n",
    "class ReplayBuffer():\n",
    "    \"\"\" Experience replay buffer to store experience tuples.\"\"\"\n",
    "    \n",
    "    def __init__(self, buffer_size, batch_size, device, seed):\n",
    "        \"\"\" Initialize replay buffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size = max buffer size\n",
    "            batch_size = size of each batch of training samples\n",
    "            device = cpu/gpu\n",
    "            seed = random seed\n",
    "        \"\"\"\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.seed = random.seed(seed)\n",
    "        self.memory = deque(maxlen=self.buffer_size)\n",
    "        self.experience = namedtuple('Experience', field_names=['state', 'action', 'next_state', 'reward', 'done'])\n",
    "    \n",
    "    def add(self, state, action, next_state, reward, done):\n",
    "        \"\"\" Add new experience tuple to memory.\"\"\"\n",
    "        e = self.experience(state, action, next_state, reward, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\" Sample a batch of experience tuples from replay buffer\"\"\"\n",
    "        experiences = random.sample(self.memory, self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if not None])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if not None])).long().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if not None])).float().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if not None])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if not None]).astype(np.uint8)).float().to(self.device)\n",
    "        \n",
    "        return (states, actions, next_states, rewards, dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\" Return length of current buffer memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/2000 Episode. Avg score 0.210\n",
      "200/2000 Episode. Avg score 3.260\n",
      "300/2000 Episode. Avg score 8.510\n",
      "400/2000 Episode. Avg score 10.080\n",
      "500/2000 Episode. Avg score 10.480\n",
      "600/2000 Episode. Avg score 12.970\n",
      "Environment solved after 605 episodes\n",
      "The first time a score >= 13 was reached at episode 198.\n",
      "Max score reached:  23.0\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(state_size, action_size, SEED)\n",
    "scores = run_dqn(agent, num_episodes=2000, eps_strt=EPS_STRT, eps_end=EPS_END, eps_decay=EPS_DECAY)\n",
    "env.close()\n",
    "\n",
    "scores = np.array(scores)\n",
    "x = np.where(scores >= 13)\n",
    "print('The first time a score >= 13 was reached at episode {}.'.format(x[0][0]))\n",
    "print('Max score reached: ', np.amax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Scores')\n",
    "plt.xlabel('Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ideas for Future Work\n",
    "\n",
    "To reach even better results one can implement:\n",
    "- Double DQN (DDQN) (paper: [Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461)),\n",
    "- Prioritized experience replay (paper: [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)), or\n",
    "- Dueling DQN (paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/abs/1511.06581)), or\n",
    "- going even further and combining improvements in RL (paper: [Rainbow: Combining Improvements in Deep Reinforcement Learning](https://arxiv.org/abs/1710.02298))\n",
    "\n",
    "\n",
    "This notebook is a project submission for the [Udacity Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893). If you are interested to learn more about Deep Reinforcement Learning - I can highly recommend it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
